import sys
import hail as hl
sys.path.insert(0, '/home/danfengc/unicorn')

from qc.utils import *
from qc.plotting import *
from main.pca import *


######################################################################################################
# This part of the code is to use to convert AJ MatrixTable to PLINK format                          #
######################################################################################################
# convert it to plink format
mt_AJ = hl.read_matrix_table('gs://unicorn-resources/Ashkenazi_Jewish_Samples/Ashkenazi_Jewish_Samples.mt')
hl.export_plink(mt_AJ,
                output='gs://unicorn-resources/Ashkenazi_Jewish_Samples/Ashkenazi_Jewish_Samples',
                varid=mt_AJ.rsid,
                cm_position=mt_AJ.cm_position)


######################################################################################################
# This part of the code is to convert 1KG PLINK BFILE to hail matrix table                           #
# The source of the 1KG PLINK bfiles:                                                                #
#    `/psych/genetics_data/ripke/references_outdated/hapmap_ref/impute2_ref/1KG_Aug12/               #
#      ALL_1000G_phase1integrated_v3_impute_macGT1/4pops/qc/pop_4pop_mix_SEQ`                        #
# It is a cleaned PLINK BFILE generated by Stephan.                                                  #
######################################################################################################
mt_1kg = hl.import_plink(bed='gs://unicorn-resources/1000_genomes/mix/mix_ready4QC_AF_HRC/mix.all.final.bed',
                         bim='gs://unicorn-resources/1000_genomes/mix/mix_ready4QC_AF_HRC/mix.all.final.bim',
                         fam='gs://unicorn-resources/1000_genomes/mix/mix_ready4QC_AF_HRC/mix.all.final.fam',
                         min_partitions=500)
mt_1kg = mt_1kg.annotate_cols(super_population=mt_1kg.fam_id.split("_")[3])
mt_1kg.write("gs://unicorn-resources/1000_genomes/pop_4pop_mix_SEQ.mt", overwrite=True)



######################################################################################################
# This part of the code is to use to generate a reference for EUR samples                            #
# The source of the 1KG BFILES can be found at                                                       #
#    `/psych/genetics_data/ripke/references_outdated/hapmap_ref/impute2_ref/1KG_Aug12/               #
#       ALL_1000G_phase1integrated_v3_impute_macGT1/4pops/qc/pop_euro_eur_SEQ`                       #
# The file `ALL_1000G_phase1integrated_feb2012.sample.nohead.fam` in the same directory contains     #
#    the population label                                                                            #
######################################################################################################
mt_eur = hl.import_plink(bed='gs://unicorn-resources/1000_genomes/eur/eur_ready4QC_AF_HRC/eur.all.final.bed',
                         bim='gs://unicorn-resources/1000_genomes/eur/eur_ready4QC_AF_HRC/eur.all.final.bim',
                         fam='gs://unicorn-resources/1000_genomes/eur/eur_ready4QC_AF_HRC/eur.all.final.fam',
                         min_partitions=500)

samples_info = hl.import_table('gs://unicorn-resources/1000_genomes/ALL_1000G_phase1integrated_feb2012.sample.nohead.fam',
    min_partitions=20, impute=True, no_header=True, delimiter ='\s+')

samples_info = samples_info.rename({'f0': 's',
                                    'f1': 's2',
                                    'f2': 'pat_id',
                                    'f3': 'mat_id',
                                    'f4': 'is_female',
                                    'f5': 'is_case',
                                    'f6': 's3',
                                    'f7': 'population',
                                    'f8': 'super_population'})
samples_info = samples_info.key_by('s')
mt_eur = mt_eur.annotate_cols(population=samples_info[mt_eur.col_key].population)
#
# create population label and write MatrixTable to disk
mt_eur = mt_eur.transmute_cols(population=hl.cond(mt_eur.population == "FIN", "fin", "eur(mainland)"))
mt_eur.write("gs://unicorn-resources/1000_genomes/pop_euro_eur_SEQ.mt", overwrite=True)


# read Ashkenazi Jewish samples
mt_AJ = hl.import_plink(bed='gs://unicorn-resources/Ashkenazi_Jewish_Samples/Ashkenazi_Jewish_Samples_ready4QC_AF_HRC/Ashkenazi_Jewish_Samples.all.final.bed',
                        bim='gs://unicorn-resources/Ashkenazi_Jewish_Samples/Ashkenazi_Jewish_Samples_ready4QC_AF_HRC/Ashkenazi_Jewish_Samples.all.final.bim',
                        fam='gs://unicorn-resources/Ashkenazi_Jewish_Samples/Ashkenazi_Jewish_Samples_ready4QC_AF_HRC/Ashkenazi_Jewish_Samples.all.final.fam',
                        min_partitions=500)
mt_AJ = mt_AJ.annotate_cols(population='aj')

# merge
mt_merged = mt_eur.select_cols('population').union_cols(mt_AJ.select_cols('population'))
pruned_variants_list = ld_prune(mt_merged, r2=0.2, pruned_variants_list=True)
pruned_variants_list.write("gs://unicorn-resources/Ashkenazi_Jewish_PCA/ld_pruned_variants.kt", overwrite=True)
pruned_variants_list = hl.read_table("gs://unicorn-resources/Ashkenazi_Jewish_PCA/ld_pruned_variants.kt")
mt_pruned = mt_merged.filter_rows(hl.is_defined(pruned_variants_list[mt_merged.row_key]), keep=True)


scores_ht, _ = pca(mt=mt_pruned, n_evecs=6, remove_outliers=False)
# Show ancestry assignment result
scores_ht = scores_ht.annotate(PC1=scores_ht.scores[0],
                               PC2=scores_ht.scores[1],
                               PC3=scores_ht.scores[2],
                               PC4=scores_ht.scores[3],
                               PC5=scores_ht.scores[4],
                               PC6=scores_ht.scores[5],
                               pop=mt_merged.index_cols(scores_ht.key).population)
scatter(ht=scores_ht, x_location='PC1', y_location='PC2', color_location='pop',
        plot_path='gs://unicorn-resources/Ashkenazi_Jewish_PCA/SCATTER_1KG_EUR_PC1_PC2.png')
scatter(ht=scores_ht, x_location='PC1', y_location='PC3', color_location='pop',
        plot_path='gs://unicorn-resources/Ashkenazi_Jewish_PCA/SCATTER_1KG_EUR_PC1_PC3.png')
scatter(ht=scores_ht, x_location='PC2', y_location='PC3', color_location='pop',
        plot_path='gs://unicorn-resources/Ashkenazi_Jewish_PCA/SCATTER_1KG_EUR_PC2_PC3.png')
scatter(ht=scores_ht, x_location='PC3', y_location='PC4', color_location='pop',
        plot_path='gs://unicorn-resources/Ashkenazi_Jewish_PCA/SCATTER_1KG_EUR_PC3_PC4.png')
scatter(ht=scores_ht, x_location='PC4', y_location='PC5', color_location='pop',
        plot_path='gs://unicorn-resources/Ashkenazi_Jewish_PCA/SCATTER_1KG_EUR_PC4_PC5.png')
scatter(ht=scores_ht, x_location='PC5', y_location='PC6', color_location='pop',
        plot_path='gs://unicorn-resources/Ashkenazi_Jewish_PCA/SCATTER_1KG_EUR_PC5_PC6.png')


# export
mt_merged = mt_eur.select_cols('population').union_cols(mt_AJ.select_cols('population'))
mt_merged.write("gs://unicorn-resources/1000_genomes/pop_euro_eur_with_aj.mt", overwrite=True)





